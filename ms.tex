\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage[left=2.5cm,top=2.5cm,right=2.5cm]{geometry}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage[utf8]{inputenc}

\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}

\newcommand{\hyperparams}{\boldsymbol{\alpha}}
\newcommand{\xx}{\boldsymbol{x}}

\title{MaxEnt: What is it good for?}
\author{Brendon J. Brewer}

\begin{document}
\maketitle

\abstract{I discuss the principle of maximum (relative) entropy as a tool
for updating probability distributions. This principle is intuitively
compelling, as I will show through examples. However, it has been neglected
by most modern practitioners of Bayesian inference. There
are two main reasons for this: i) some questionable applications
and discussions of the principle have appeared in the literature, and
ii) the situation which the principle seems designed to handle never seems
to actually arise in practical applications. I will attempt to define the
situations in which MaxEnt could be practically useful.}

\section{Introduction}
The principle of maximum entropy (MaxEnt) is an idea in probability theory
that is usually associated with \citet{jaynes}, although it has appeared in
various guises in the work of others \citep[e.g.][]{gibbs, boltzmann, shannon}.

The principle may be used
to {\it assign} or {\it update} a
subjective\footnote{in the sense that the probability distribution is a model
of the state of uncertainty of an idealised rational agent, rather than
a {\it frequency distribution} such as a histogram of people's heights.}
probability distribution when you obtain a certain kind of information
called {\it testable information}. In this article I will focus on the
updating application, as the assigning application can be viewed as a special
case where the prior distribution happened to be
uniform\footnote{A uniform probability distribution, either over a discrete
hypothesis space, or a continuous one with respect to a specific choice of
parameterisation, may be justified by a symmetry argument, or simply asserted
as in the ``subjective Bayesian'' approach.}.

The principle is very intuitively compelling
and there are some axiomatic arguments in its favour
\citep[e.g.][]{2010arXiv1008.4831K}. However, MaxEnt has also been widely
misapplied (even by some of its staunchest defenders), misunderstood,
and poorly defended (at times, even by Jaynes himself).
Consequently, most modern Bayesians pay little attention to the principle,
although there is a tendency among physicists to invoke it as a justification
for a prior distribution (be it uniform, exponential, gaussian, or whatever).
The purpose of this article is to explore the principle from the point of
view of a Bayesian practitioner, discuss some of the properties that
make MaxEnt compelling, and propose some ideas about how it could be used in
practice.

Throughout this article I will present, but not derive or prove, MaxEnt
results for certain types of testable information. Some of these are well
known (e.g. the expected value constraints discussed in
Section~\ref{sec:expected_values}, which lead to ``canonical'' probability
distributions which may be familiar from statistical mechanics) while others
are less so. Where possible I will present other results as special cases of
the canonical distribution.

\section{Probability}
We start with a {\it hypothesis space} of mutually exclusive and
exhaustive propositions $A_1$, $A_2$, ..., $A_N$ which we will usually
think of as possible values of an unknown quantity $x$. For example,
$A_1 \equiv $``$x=1$'', $A_2 \equiv $``$x=2$'', and so on.
On the basis of background
information $I$ (hereafter suppressed), we know that one and only one of these
propositions is true (i.e. the true value of $x$ is in our hypothesis space),
but we don't know which. We model states of
uncertainty by probability distributions over the hypothesis space,
such as $\{p_i\}_{i=1}^N$ where $P(A_i) = p_i$ is the probability of $A_i$.
In the standard loose Bayesian notation we write this distribution simply
as $p(x)$.

Of course, $p(x)$ must be non-negative and sum to 1.
From this probability distribution, various probabilities can be derived
using the sum and product rules. For example, the probability of
($A_4$ {\bf or} $A_5$) is $p_4 + p_5$, and the probability of $A_5$ given
($A_5$ {\bf or} $A_8$) is $p_5/(p_5 + p_8)$. The rules of probability must
be obeyed if the rules for combining are to remain consistent
with the symmetries of logical {\bf and} and {\bf or}
\citep{2010arXiv1008.4831K}.

\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{distribution.pdf}
\caption{A prior distribution $q(x)$, which we will use
update to a posterior $p(x)$ given different kinds of testable information.
\label{fig:distribution}}
\end{center}
\end{figure}

The relative entropy of distribution $p$ from distribution $q$ is:
\begin{eqnarray}
H(p; q) &=& -\sum_i p_i \log\left(\frac{p_i}{q_i}\right) 
\end{eqnarray}
Intuitively, $H$ measures how close the probability distribution $p$ is
to the distribution $q$. The maximum possible value of $H$ is zero, if
and only if $p$ happens to be the same as $q$.
However, it is not symmetric and does not satisfy
other properties of a distance.
and we are to choose the distribution $p$ to maximise $H$ subject to the
constraints of normalisation and any other constraints.

\section{What is testable information?}
{\it Testable information} refers to information given in the form of
{\it a constraint that our probability distribution should satisfy}. This is
different from the kind of information we normally use in Bayesian inference,
which is the truth of a proposition. An example of testable information
might be $P(x > 7) = 0.4$. That is, our probability distribution should have
the property that there's a 40\% probability of $x$ being greater than 7.
If our current (prior) probability distribution $q$ already has this property,
then we needn't do anything. However, if $q$ does not satisfy this property,
we use MaxEnt to choose a new distribution, the posterior $p$.

The posterior $p$ will satisfy the constraint given in the testable information,
and will be as close to $q$ as possible while doing so.



\section{Special case 1: expected values}\label{sec:expectations}
The most common kind of testable information analysed using MaxEnt is
expected values. An expected value is a property of a probability distribution,
and we can imagine updating from a prior $q$ to a posterior
$p$ when we receive information that specifies an expected value.
For example, suppose we apply the constraint (the testable information)
that the expected value of $f(x)$ should equal some known value $F$. That is:
\begin{eqnarray}
\left<f(x)\right>_p = \sum_x p(x)f(x) = F.\label{eq:expected_value}
\end{eqnarray}

The resulting posterior distribution given by MaxEnt is:
\begin{eqnarray}
p(x) &=& \frac{1}{Z}q(x)\exp\left[-\lambda f(x)\right] 
\end{eqnarray}
That is, the posterior is proportional to the prior multiplied by a
``canonical'' factor. The value of $\lambda$ must be chosen so that
the constraint (Equation~\ref{eq:expected_value}) is satisfied. $Z$ is the
normalisation constant and implicitly depends on $\lambda$.

As an example, let's update the prior from Figure~\ref{fig:distribution}
using the testable information $\left<(x - 5)^2\right>_p = 1$. The appropriate
value of the lagrange multiplier is $\lambda=0.5163846$, and the posterior is
shown in Figure~\ref{fig:distribution3}.
\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{distribution3.pdf}
\caption{\label{fig:distribution3}}
\end{center}
\end{figure}


\subsection{The ``constraint rule'' controversy}
Is it valid to use an experimental average (literally the arithmetic mean of
some data) to set the expected value of a probability distribution? The
assumption that this is okay has been termed {\it the constraint rule}.

In many presentations of MaxEnt, it is assumed that this is not a problem
({\bf cite people}). Other authors have noticed that it's possible to
condition on the observed arithmetic mean, as one would do in a standard
Bayesian analysis of that information, and that this can lead to a different
answer from the constraint rule.


This has led to the widespread (and in my view, incorrect) belief that
MaxEnt and Bayesian inference are ``incompatible'', and the 

{\bf Brandeis dice problem...MaxEnt solution vs. ``the'' Bayesian solution}


{\bf Mention Niven and ``combinatorics'' -- it's just the sum rule then. not
a new principle}.

\section{A special case: updating given propositions}
Consider the following testable information:

\begin{eqnarray}
P(D) = 1
\end{eqnarray}
where $D$ is a proposition about the value of $x$. For example, consider
updating from the prior $q(x)$ shown in Figure~\ref{fig:distribution}, to
a posterior $p(x)$, using the testable information
\begin{eqnarray}
P(3 \leq x \leq 5) = 1.\label{eq:prob_one}
\end{eqnarray}
Clearly, the distribution $q(x)$ doesn't satisfy this constraint. According
to $q(x)$ the probability that $x$ is 3, 4, or 5 is 0.225, not 1.
Therefore, we
need to update to a new distribution $p(x)$ using MaxEnt. It may not be
immediately obvious, but Equation~\ref{eq:prob_one} can be viewed as
a constraint on an expected value:
\begin{eqnarray}
\left<
\mathds{1}\left(3 \leq x \leq 5\right)
\right>_p = 1.
\end{eqnarray}
where $\mathds{1}()$ is an indicator function which returns 1 where the
argument is true and 0 where it is false. This allows us to use the
result for expected value constraints, given in
Section~\ref{sec:expectations}.


\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{distribution2.pdf}
\caption{\label{fig:distribution2}}
\end{center}
\end{figure}

\subsection{Skilling's criticism}
Skilling thinks this is ``deriving Bayes again, when it's already there
as the product rule''. I consider it more as a demonstration of which
particular constraints are epistemically equivalent to learning the
truth of a propositions. It turns out to be the rather obvious constraint
that the probability we should assign to a proposition we know to be true
is 1.

I also think this viewpoint clarifies thinking about the ``probability
distribution for the data'' (interpretation of sampling distributions etc).

\section{MaxEnt with constraints on conditionals: the ``entropic prior''}


\section{MaxEnt with constraints on marginals: ``hierarchical Bayes''}
Suppose we have a discrete prior distribution $q(\xx)$. Consider some
function of the unknown quantity, $f(\xx)$.
If the value of $f(\xx)$ is known, then our distribution for $\xx$ can
be updated from $q$ to $p$ as in Section~\ref{sec:bayes}.
If we receive testable information
about the expected value of $F$, then our distribution for $\xx$ can
be updated as in Section~\ref{sec:expectations}.

In this section we'll look at a different kind of testable information that
relates to $F$, but is not the expected value. What if we receive testable
information that asserts the marginal distribution for $F$?
For any distribution $p(\xx)$, the marginal distribution for $F$ is:
\begin{eqnarray}
p(F) &=& \sum_{\xx}\mathds{1}\left[f(\xx) = F\right]p(\xx)\label{eqn:constraint}
\end{eqnarray}
If $p(F)$ is a specified function, this is a large number of expected
value constraints on $p(\xx)$, one for each element of the hypothesis space
of possible $F$ values. Clearly, the specified marginal $p(F)$ cannot assign
non-zero probability to any possible $F$ values that have zero probability
under $q(\xx)$.

Since Equation~\ref{eqn:constraint} is really just a set of expectations,
the probability distribution
$p(\xx)$ with maximum entropy with respect to $q(\xx)$ that satisfies the
constraint~\ref{eqn:constraint} is:
\begin{eqnarray}
p(\xx) &=& \frac{q(\xx)}{Z}\exp\left\{-\sum_F \lambda_F \mathds{1}
\left[f(\xx) = F\right]  \right\}
\end{eqnarray}


\section{Where is testable information in the real world?}

Example about hearing ``sí/si'' as an answer to a question,
and inferring the language (Spanish or French).

The joint prior is:

\begin{eqnarray}
\begin{array}{|c|c|c|}
\hline
	&	S	& \bar{S}\\
\hline
H_1 & 0.25  & 0.25\\
\hline
H_2 & 0.05 & 0.45\\
\hline
\end{array}
\end{eqnarray}

The marginal probabilities for $H_1$ and $H_2$ are both 0.5, and the
marginal probabilities for $S$ and $\bar{S}$ are 0.3 and 0.7 respectively.



\section*{Acknowledgements}
It is a pleasure to thank
Ariel Caticha (Albany),
Adom Giffin (Clarkson)
John Skilling (MaxEnt Data Consultants),
Carlos Rodriguez (Albany),
Stephen Gull (Cambridge),
Kevin Knuth (Albany),
Iain Murray (Edinburgh),
Anna Pancoast (UCSB),
Geraint Lewis (Sydney),
David Hogg (NYU),
Robert Niven (UNSW),
Tom Loredo (Cornell),
Daniela Huppenkothen (NYU),
Peter Tuthill (Sydney),
and John Wilcox (Auckland)
for valuable discussions.


\begin{thebibliography}{}
\bibitem[Caticha(2008)]{2008arXiv0808.0012C} Caticha, A.\ 2008.\ Lectures 
on Probability, Entropy, and Statistical Physics.\ ArXiv e-prints 
arXiv:0808.0012. 

\bibitem[Caticha and Giffin(2006)]{2006AIPC..872...31C} Caticha, A., 
Giffin, A.\ 2006.\ Updating Probabilities.\ Bayesian Inference and Maximum 
Entropy Methods In Science and Engineering 872, 31-42.

\bibitem[Gibbs(1914)]{gibbs} Gibbs, J.~W.~Elementary Principles in
Statistical Mechanics: Developed with Special Reference to the Rational
Foundations of Thermodynamics. Yale University Press, 1914.

\bibitem[Giffin and Caticha(2007)]{2007AIPC..954...74G} Giffin, A., 
Caticha, A.\ 2007.\ Updating Probabilities with Data and Moments.\ Bayesian 
Inference and Maximum Entropy Methods in Science and Engineering 954, 
74-84.

\bibitem[Jaynes(1979)]{stand_on_entropy} Jaynes, E. T., 1979, ``Where do we Stand on Maximum Entropy?'' in The Maximum Entropy Formalism, R. D. Levine and M. Tribus (eds.), M. I. T. Press, Cambridge, MA, p. 15

\bibitem[Jaynes(2003)]{jaynes} Jaynes, E. T., 2003, ``Probability Theory:
The Logic of Science'', ed. G.~Larry~Bretthorst, Cambridge University Press

\bibitem[Knuth and Skilling(2010)]{2010arXiv1008.4831K} Knuth, K.~H., 
Skilling, J.\ 2010.\ Foundations of Inference.\
Axioms 1.1 (2012): 38-73.\
ArXiv e-prints arXiv:1008.4831. 
\end{thebibliography}

\end{document}

