\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage[left=2.5cm,top=2.5cm,right=2.5cm]{geometry}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage[utf8]{inputenc}
\usepackage{color, colortbl}

\definecolor{Gray}{gray}{0.5}
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}

\newcommand{\hyperparams}{\boldsymbol{\alpha}}
\newcommand{\xx}{\boldsymbol{x}}

\title{MaxEnt: What is it good for?}
\author{Brendon J. Brewer}

\begin{document}
\maketitle

\abstract{I discuss the principle of maximum (relative) entropy as a tool
for updating probability distributions. This principle is intuitively
compelling, as I will show through examples. However, it has been neglected
by most modern practitioners of Bayesian inference. There
are two main reasons for this: i) some questionable applications
and discussions of the principle have appeared in the literature, and
ii) the situation which the principle seems designed to handle never seems
to actually arise in practical applications. I will attempt to define the
situations in which MaxEnt could be practically useful.}

\section{Introduction}
It is now well established that degrees of certainty can and should be modelled
with probability theory. The resulting framework is usually called Bayesian
inference, whose key feature is the updating of probabilities to incorporate
new information when it is learned.

The principle of maximum entropy (MaxEnt) is an idea that was developed...

It is usually associated with \citet{jaynes}, although it has appeared in
various guises in the work of others \citep[e.g.][]{gibbs, boltzmann, shannon}.

MaxEnt can be used either to {\it assign} or to {\it update} a
subjective\footnote{in the sense that the probability distribution is a model
of the state of uncertainty of an idealised rational agent, rather than
a {\it frequency distribution} such as a histogram of people's heights.}
probability distribution when you obtain a certain kind of information
called {\it testable information}. In this article I will focus on the
updating application, as the assigning application can be viewed as a special
case where the prior distribution happened to be
uniform\footnote{A uniform probability distribution, either over a discrete
hypothesis space, or a continuous one with respect to a specific choice of
parameterisation, may be justified by a symmetry argument, or simply asserted
as in the ``subjective Bayesian'' approach.}.

There are some axiomatic arguments supporting MaxEnt
\citep[e.g.][]{shore_johnson, 2006AIPC..872...31C, 2010arXiv1008.4831K},
as well as counterexamples to possible alternatives \citep[e.g.][]{presse}.
However, there is no consensus among Bayesians about the status of MaxEnt. Is
it a valid and potentially useful fundamental principle, some kind of an
approximation or computational trick, or a dead end that is only of
historical interest?

There are several possible reasons for the lack of consensus. 
One is that the name ``MaxEnt'' has been used to refer not just to the principle
for updating probability distributions, but also to a specific choice of
regularisation term in optimisation-based methods for inverse problems
\citep{}, among other things. Since Bayesian inference is
a more principled way to deal with the uncertainty than regularised
optimisation, MaxEnt seems obsolete --- although it is obvious that
an argument against one idea does not imply much about another idea that
happens to share the same name.
In addition, many defences and explanations of MaxEnt in the literature
are weak.

Consequently, most modern Bayesians pay little attention to the principle,
although there is a tendency among physicists, raised on \citet{jaynes},
to invoke it as a justification
for a prior distribution (be it uniform, exponential, gaussian, or whatever).
The purpose of this article is to explore the principle from the point of
view of a Bayesian practitioner, discuss some of the properties that
make MaxEnt compelling, and propose some ideas about how it could be used in
practice.

Throughout this article I will present, but not derive or prove, MaxEnt
results for certain types of testable information. Some of these are well
known (e.g. the expected value constraints discussed in
Section~\ref{sec:expected_values}, which lead to ``canonical'' probability
distributions which may be familiar from statistical mechanics) while others
are less so. Where possible I will present other results as special cases of
the canonical distribution.

\section{Probability}
We start with a {\it hypothesis space} of mutually exclusive and
exhaustive propositions which we can (without loss of generality)
think of as possible values of an unknown quantity $x$. For example,
the propositions might be ``$x=1$'', ``$x=2$'', and so on.
On the basis of background
information $I$ (hereafter suppressed), we know that one and only one of these
propositions is true (i.e. the true value of $x$ is in our hypothesis space),
but we don't know which. We model states of
uncertainty by probability distributions over the hypothesis space,
such as $\{p_i\}_{i=1}^N$ where $P(x=x_i) = p_i$.
In the standard loose Bayesian notation we write this distribution simply
as $p(x)$, the probability distribution for $x$.

Of course, $p(x)$ must be non-negative and sum to 1 in order to be a valid
probability distribution.
From this probability distribution, various probabilities can be derived
using the sum and product rules. For example, the probability of
($x=4$ {\bf or} $x=5$) is $p_4 + p_5$, and the probability of $x=5$ given
($x=5$ {\bf or} $x=8$) is $p_5/(p_5 + p_8)$. The rules of probability must
be obeyed if the rules for combining are to remain consistent
with the symmetries of logical {\bf and} and {\bf or}
\citep{2010arXiv1008.4831K}.

The relative entropy of distribution $p$ from distribution $q$ is:
\begin{eqnarray}
H(p; q) &=& -\sum_i p_i \log\left(\frac{p_i}{q_i}\right) 
\end{eqnarray}
Intuitively, $H$ measures how close the probability distribution $p$ is
to the distribution $q$. The maximum possible value of $H$ is zero, if
and only if $p$ happens to be the same as $q$.
However, $H$ is not symmetric and does not satisfy
other properties of a distance.

Throughout this paper, we will look at examples of MaxEnt updating from a prior
$q(x)$ to a posterior $p(x)$ in different situations where the available
information takes different forms. The prior distribution for all of the
examples is a discrete prior over nine possible values of $x$, and is shown
in Figure~\ref{fig:distribution}. The nine prior probabilities are:

\begin{eqnarray}
\boldsymbol{q} = \{0.059, 0.167, 0.117, 0.048, 0.076, 0.231, 0.030, 0.082, 0.191\}.
\end{eqnarray}

The reason for choosing a ``ragged'' distribution is to avoid making any
connection between MaxEnt and notions of smoothness or locality, since these
do not actually play a role.

\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{distribution.pdf}
\caption{A prior distribution $q(x)$, which we will use
update to a posterior $p(x)$ given different kinds of testable information.
\label{fig:distribution}}
\end{center}
\end{figure}


\section{What is testable information?}
{\it Testable information} refers to information given in the form of
{\it a constraint that our probability distribution should satisfy}. This is
the kind of information MaxEnt uses, and is
different from the kind of information we normally use in Bayesian inference,
which is the truth of a proposition. An example of testable information
might be $P(x > 7) = 0.4$. That is, our probability distribution should have
the property that there's a 40\% probability of $x$ being greater than 7.
If our current (prior) probability distribution $q$ already has this property,
then we needn't do anything. However, if $q$ does not satisfy this property,
we use MaxEnt to choose a new distribution, the posterior $p$.

The posterior $p$ must satisfy the constraint given in the testable information,
and should be as close to $q$ as possible while doing so. The criterion for
``closeness'' is the relative entropy $H(p; q)$:
we should choose the distribution $p$ to maximise $H$ subject to the
constraints of normalisation (i.e. $\sum_i q_i = 1$)
and the testable information.


\section{Special case 1: expected values}\label{sec:expectations}
The most common kind of testable information analysed using MaxEnt is
expected values. An expected value is a property of a probability distribution,
and we can imagine updating from a prior $q$ to a posterior
$p$ when we receive information that specifies an expected value.
For example, suppose we apply the constraint (the testable information)
that the expected value of $f(x)$ should equal some known value $F$. That is:
\begin{eqnarray}
\left<f(x)\right>_p = \sum_x p(x)f(x) = F.\label{eq:expected_value}
\end{eqnarray}

The resulting posterior distribution given by MaxEnt is:
\begin{eqnarray}
p(x) &=& \frac{1}{Z}q(x)\exp\left[-\lambda f(x)\right] 
\end{eqnarray}
That is, the posterior is proportional to the prior multiplied by a
``canonical'' factor. The value of $\lambda$ must be chosen so that
the constraint (Equation~\ref{eq:expected_value}) is satisfied. $Z$ is the
normalisation constant and implicitly depends on $\lambda$.

As an example, let's update the prior from Figure~\ref{fig:distribution}
using the testable information $\left<(x - 5)^2\right>_p = 1$. The appropriate
value of the lagrange multiplier is $\lambda=0.516375$, and the posterior is
shown in Figure~\ref{fig:distribution3}.
\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{distribution3.pdf}
\caption{\label{fig:distribution3}}
\end{center}
\end{figure}


\subsection{The ``constraint rule'' controversy}
Is it valid to use an experimental average (literally the arithmetic mean of
some data) to set the expected value of a probability distribution? The
assumption that this is okay has been termed {\it the constraint rule}, which
has been discussed in depth by \citet{uffink}.

In many presentations of MaxEnt, it is assumed that this is not a problem.
For example, \citet{jaynes} often motivated MaxEnt using an example of a
non-standard six-sided die, and we are asked to assign a probability
distribution for the result of the next toss, using the information that the
historical average of the tosses is 4.5 instead of the 3.5 one would
usually expect.


Other authors have noticed that it's possible to
condition on the observed arithmetic mean, as one would do in a standard
Bayesian analysis of that information, and that this can lead to a different
answer from the constraint rule.


This has led to the widespread (and in my view, incorrect) belief that
MaxEnt and Bayesian inference are ``incompatible'', and the 

{\bf Brandeis dice problem...MaxEnt solution vs. ``the'' Bayesian solution}


{\bf Mention Niven and ``combinatorics'' -- it's just the sum rule then. not
a new principle}.

\section{A special case: updating given propositions}
Consider the following testable information:

\begin{eqnarray}
P(D) = 1
\end{eqnarray}
where $D$ is a proposition about the value of $x$. For example, consider
updating from the prior $q(x)$ shown in Figure~\ref{fig:distribution}, to
a posterior $p(x)$, using the testable information
\begin{eqnarray}
P(7 \leq x \leq 9) = 1.\label{eq:prob_one}
\end{eqnarray}
Clearly, the distribution $q(x)$ doesn't satisfy this constraint. According
to $q(x)$ the probability that $x$ is 7, 8, or 9 is 0.303, not 1.
Therefore, we
need to update to a new distribution $p(x)$ using MaxEnt. It may not be
immediately obvious, but Equation~\ref{eq:prob_one} can be viewed as
a constraint on an expected value:
\begin{eqnarray}
\left<
\mathds{1}\left(7 \leq x \leq 9\right)
\right>_p = 1.
\end{eqnarray}
where $\mathds{1}()$ is an indicator function which returns 1 where the
argument is true and 0 where it is false. This allows us to use the
result for expected value constraints, given in
Section~\ref{sec:expectations}.


\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{distribution2.pdf}
\caption{\label{fig:distribution2}}
\end{center}
\end{figure}

The prior probabilities can also be laid out in a grid:

\begin{center}
\begin{tabular}{|ccc|}
\hline
0.059 & 0.167 & 0.117\\
0.048 & 0.076 & 0.231\\
0.030 & 0.082 & 0.191\\
\hline
\end{tabular}
\end{center}

Updating using MaxEnt, using the same constraint as before, is equivalent
to ruling out the first two rows of this grid and maintaining the third.
\begin{center}
\begin{tabular}{|ccc|}
\hline
\rowcolor{Gray}
0.059 & 0.167 & 0.117\\
\rowcolor{Gray}
0.048 & 0.076 & 0.231\\
0.030 & 0.082 & 0.191\\
\hline
\end{tabular}
$\Longrightarrow$
\begin{tabular}{|ccc|}
\hline
0.000 & 0.000 & 0.000\\
0.000 & 0.000 & 0.000\\
0.099 & 0.270 & 0.630\\
\hline
\end{tabular}
\end{center}

In Bayesian inference, we usually want to infer the value of a parameter
$\theta$ from the value of a datum $D$. Suppose there are three possible
$\theta$ values ($\theta_1$, $\theta_2$, and $\theta_3$) and three possible
$D$ values ($D_1$, $D_2$, and $D_3$). Then the hypothesis space
consists of nine propositions, created using logical {\bf and}; these
propositions are all of the form
$(\theta = \theta_i) \wedge (D = D_j)$ where $i, j \in \{1, 2, 3\}$.


\subsection{Skilling's criticism}
Skilling thinks this is ``deriving Bayes again, when it's already there
as the product rule''. I consider it more as a demonstration of which
particular constraints are epistemically equivalent to learning the
truth of a propositions. It turns out to be the rather obvious constraint
that the probability we should assign to a proposition we know to be true
is 1.

I also think this viewpoint clarifies thinking about the ``probability
distribution for the data'' (interpretation of sampling distributions etc).

\section{MaxEnt with constraints on conditionals: the ``entropic prior''}


\section{MaxEnt with constraints on marginals}
\subsection{Heirarchical Bayes}
Suppose we have a discrete prior distribution $q(\xx)$. Consider some
function of the unknown quantity, $f(\xx)$.
If the value of $f(\xx)$ is known, then our distribution for $\xx$ can
be updated from $q$ to $p$ as in Section~\ref{sec:bayes}.
If we receive testable information
about the expected value of $F$, then our distribution for $\xx$ can
be updated as in Section~\ref{sec:expectations}.

In this section we'll look at a different kind of testable information that
relates to $F$, but is not the expected value. What if we receive testable
information that asserts the marginal distribution for $F$?
For any distribution $p(\xx)$, the marginal distribution for $F$ is:
\begin{eqnarray}
p(F) &=& \sum_{\xx}\mathds{1}\left[f(\xx) = F\right]p(\xx)\label{eqn:constraint}
\end{eqnarray}
If $p(F)$ is a specified function, this is a large number of expected
value constraints on $p(\xx)$, one for each element of the hypothesis space
of possible $F$ values. Clearly, the specified marginal $p(F)$ cannot assign
non-zero probability to any possible $F$ values that have zero probability
under $q(\xx)$.

Since Equation~\ref{eqn:constraint} is really just a set of expectations,
the probability distribution
$p(\xx)$ with maximum entropy with respect to $q(\xx)$ that satisfies the
constraint~\ref{eqn:constraint} is:
\begin{eqnarray}
p(\xx) &=& \frac{q(\xx)}{Z}\exp\left\{-\sum_F \lambda_F \mathds{1}
\left[f(\xx) = F\right]  \right\}
\end{eqnarray}

\subsection{Jeffrey Conditionalisation}


\section{Where is testable information in the real world?}

Example about hearing ``sí/si'' as an answer to a question,
and inferring the language (Spanish or French).

The joint prior is:

\begin{eqnarray}
\begin{array}{|c|c|c|}
\hline
	&	S	& \bar{S}\\
\hline
H_1 & 0.25  & 0.25\\
\hline
H_2 & 0.05 & 0.45\\
\hline
\end{array}
\end{eqnarray}

The marginal probabilities for $H_1$ and $H_2$ are both 0.5, and the
marginal probabilities for $S$ and $\bar{S}$ are 0.3 and 0.7 respectively.



\section*{Acknowledgements}
It is a pleasure to thank
Ariel Caticha (Albany),
Adom Giffin (Clarkson)
John Skilling (MaxEnt Data Consultants),
Carlos Rodriguez (Albany),
Stephen Gull (Cambridge),
Kevin Knuth (Albany),
Iain Murray (Edinburgh),
Anna Pancoast (UCSB),
Geraint Lewis (Sydney),
David Hogg (NYU),
Robert Niven (UNSW),
Tom Loredo (Cornell),
Daniela Huppenkothen (NYU),
Peter Tuthill (Sydney),
and John Wilcox (Auckland)
for valuable discussions.


\begin{thebibliography}{}
\bibitem[Caticha(2008)]{2008arXiv0808.0012C} Caticha, A.\ 2008.\ Lectures 
on Probability, Entropy, and Statistical Physics.\ ArXiv e-prints 
arXiv:0808.0012. 

\bibitem[Caticha and Giffin(2006)]{2006AIPC..872...31C} Caticha, A., 
Giffin, A.\ 2006.\ Updating Probabilities.\ Bayesian Inference and Maximum 
Entropy Methods In Science and Engineering 872, 31-42.

\bibitem[Gibbs(1914)]{gibbs} Gibbs, J.~W.~Elementary Principles in
Statistical Mechanics: Developed with Special Reference to the Rational
Foundations of Thermodynamics. Yale University Press, 1914.

\bibitem[Giffin and Caticha(2007)]{2007AIPC..954...74G} Giffin, A., 
Caticha, A.\ 2007.\ Updating Probabilities with Data and Moments.\ Bayesian 
Inference and Maximum Entropy Methods in Science and Engineering 954, 
74-84.

\bibitem[Jaynes(1979)]{stand_on_entropy} Jaynes, E. T., 1979, ``Where do we Stand on Maximum Entropy?'' in The Maximum Entropy Formalism, R. D. Levine and M. Tribus (eds.), M. I. T. Press, Cambridge, MA, p. 15

\bibitem[Jaynes(2003)]{jaynes} Jaynes, E. T., 2003, ``Probability Theory:
The Logic of Science'', ed. G.~Larry~Bretthorst, Cambridge University Press

\bibitem[Knuth and Skilling(2010)]{2010arXiv1008.4831K} Knuth, K.~H., 
Skilling, J.\ 2010.\ Foundations of Inference.\
Axioms 1.1 (2012): 38-73.\
ArXiv e-prints arXiv:1008.4831. 

\bibitem[Pressé et al(2013)]{presse}
Pressé, S., et al. ``Nonadditive entropies yield probability distributions with biases not warranted by the data.'' Physical review letters 111.18 (2013): 180604.

\bibitem[Shore and Johnson(1980)]{shore_johnson}
Shore, J.E., and Johnson, R.. ``Axiomatic derivation of the principle of maximum entropy and the principle of minimum cross-entropy.'' Information Theory, IEEE Transactions on 26.1 (1980): 26-37.

\bibitem[Uffink(1996)]{uffink} Uffink,~J. ``The constraint rule of the maximum entropy principle.'' Studies in History and Philosophy of Science Part B: Studies in History and Philosophy of Modern Physics 27.1 (1996): 47-79.
\end{thebibliography}

\end{document}

